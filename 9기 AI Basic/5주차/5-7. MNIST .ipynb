{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55e10c8b",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "- 28 x 28 image\n",
    "- 1 channel gray image\n",
    "- 0 ~ 9 digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b4259",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b5344d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (2.28.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737ad637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac7c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "mnist_train=dset.MNIST(root='MNIST_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test=dset.MNIST(root='MNIST_data/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "data_loader=torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee8f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    # reshape input image into [batch_size by 784]\n",
    "    # label is not one-hot encoded\n",
    "    X=X.view(-1, 28*28).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42fc29",
   "metadata": {},
   "source": [
    "# Epoch / Batch size / Iteration\n",
    "- epoch: 전체 데이터의 학습 횟수\n",
    "- batch size: 몇 개씩 학습할 지\n",
    "- iteration: batch 사용 횟수\n",
    "- ex) 1000개의 train set이 있을 때, 1 epoch에 batch size=500, iteration=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5d4b9",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3370efd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost= 0.536887348\n",
      "Epoch:  0002 cost= 0.359124303\n",
      "Epoch:  0003 cost= 0.331245780\n",
      "Epoch:  0004 cost= 0.316526026\n",
      "Epoch:  0005 cost= 0.307073027\n",
      "Epoch:  0006 cost= 0.300273120\n",
      "Epoch:  0007 cost= 0.295047194\n",
      "Epoch:  0008 cost= 0.290754229\n",
      "Epoch:  0009 cost= 0.287258238\n",
      "Epoch:  0010 cost= 0.284556389\n",
      "Epoch:  0011 cost= 0.281915605\n",
      "Epoch:  0012 cost= 0.279633641\n",
      "Epoch:  0013 cost= 0.277664304\n",
      "Epoch:  0014 cost= 0.276000142\n",
      "Epoch:  0015 cost= 0.274360329\n"
     ]
    }
   ],
   "source": [
    "# MNIST data image of shape 28*28=784\n",
    "linear=torch.nn.Linear(784, 10, bias=True).to(device) # 이미지크기, 클래스개수\n",
    "\n",
    "# parameters\n",
    "training_epochs=15\n",
    "batch_size=100\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "criterion=torch.nn.CrossEntropyLoss().to(device) # Softmax is internally computed.\n",
    "optimizer=torch.optim.SGD(linear.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost=0\n",
    "    total_batch=len(data_loader)\n",
    "    for X,Y in data_loader:\n",
    "        # reshpae input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X=X.view(-1, 28*28).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis=linear(X)\n",
    "        cost=criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=cost/total_batch\n",
    "        \n",
    "    print('Epoch: ', \"%04d\" % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b28907",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63acda09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.883400022983551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\user\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "with torch.no_grad():\n",
    "    X_test=mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
    "    Y_test=mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction=linear(X_test)\n",
    "    correct_prediction=torch.argmax(prediction, 1)==Y_test\n",
    "    accuracy=correct_prediction.float().mean()\n",
    "    print('Accuracy: ', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6b6e2",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f56d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\datasets\\mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\user\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\datasets\\mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  4\n",
      "Prediction:  4\n"
     ]
    }
   ],
   "source": [
    "r=random.randint(0, len(mnist_test) - 1)\n",
    "\n",
    "X_single_data=mnist_test.test_data[r:r+1].view(-1,28*28).float().to(device)\n",
    "Y_single_data=mnist_test.test_labels[r:r+1].to(device)\n",
    "\n",
    "print('Label: ', Y_single_data.item())\n",
    "single_prediction=linear(X_single_data)\n",
    "print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "plt.imshow(mnist_test.test_data[r:r+1].view(28,28),cmap='Greys',interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e899e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
